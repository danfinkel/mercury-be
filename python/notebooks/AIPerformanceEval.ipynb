{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/danfinkel/github/mercury-be/\") \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import use\n",
    "from python.tools.turbo4 import Turbo4\n",
    "from python.tools.teachable import Teachable_Turbo4\n",
    "from python.tools.llmtypes import Chat, TurboTool\n",
    "from python.tools import rand\n",
    "from python.tools.instruments import AgentInstruments\n",
    "from python.tools.llm import add_cap_ref\n",
    "from python.tools.llm import getTableDefs\n",
    "from python.tools.helpers import run_python\n",
    "\n",
    "\n",
    "from typing import List, Callable\n",
    "import os\n",
    "import argparse\n",
    "import dotenv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env vars\n",
    "# tmp = os.getcwd()\n",
    "# os.chdir(\"/Users/danfinkel/github/mercury-be/\")\n",
    "# print(os.getcwd())\n",
    "dotenv.load_dotenv(\"/Users/danfinkel/github/mercury-be/\")\n",
    "# os.chdir(tmp)\n",
    "\n",
    "# check to make sure the important env vars are set\n",
    "assert os.environ.get(\"RENDER_PG_URL\"), \"POSTGRES_CONNECTION_URL not found in .env file\"\n",
    "assert os.environ.get(\"RENDER_PG_SCHEMA\"), \"DATABASE_SCHEMA not found in .env file\"\n",
    "\n",
    "# bring env variables into memory\n",
    "DB_URL = os.environ.get(\"RENDER_PG_URL\")\n",
    "DATABASE_SCHEMA = os.environ.get(\"RENDER_PG_SCHEMA\")\n",
    "POSTGRES_TABLE_DEFINITION_CAP_REF = \"TABLE_DEFINITIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table definitions for tables to be used for test\n",
    "table_definitions = getTableDefs(DB_URL, DATABASE_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_function_tool_config = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"run_python\",\n",
    "        \"description\": \"This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"pythonScript\": {\"type\": \"string\"}},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAI(raw_prompt: str, ii: int = 0) -> str:\n",
    "    \n",
    "    assistant_name = \"Turbo4\"\n",
    "    assistant = Turbo4()\n",
    "    \n",
    "    ai_tools = [\n",
    "        TurboTool(\"run_python\", custom_function_tool_config, run_python),\n",
    "    ]\n",
    "\n",
    "    prompt = add_cap_ref(\n",
    "    \"\", # type: ignore\n",
    "    f\"Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_{str(ii)}.csv\",\n",
    "    \"QUESTION:\",\n",
    "    raw_prompt\n",
    "    )\n",
    "\n",
    "    prompt = add_cap_ref(\n",
    "        prompt,  # type: ignore\n",
    "        f\"\\n\\nThe data you need to execute the task can be found in a postgres database with {POSTGRES_TABLE_DEFINITION_CAP_REF} described below.\", \n",
    "        POSTGRES_TABLE_DEFINITION_CAP_REF, \n",
    "        table_definitions # type: ignore\n",
    "    )    \n",
    "\n",
    "    prompt += '\\n\\n Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\\nhost: RENDER_PG_HOST\\ndatabase: RENDER_PG_NAME\\nusername: RENDER_PG_USER\\npassword: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.'\n",
    "\n",
    "    print('Starting the assistant...')\n",
    "    assistant, status_msg = assistant.get_or_create_assistant(assistant_name)\n",
    "\n",
    "    print('Setting the instructions...')\n",
    "    assistant, instruct_msg = assistant.set_instructions(\"You are an elite python developer that specializes in adtech. You generate the most concise and performant python scripts.\") # type: ignore\n",
    "\n",
    "    print('Equipping the assistant...')\n",
    "    assistant = assistant.equip_tools(ai_tools, equip_on_assistant=False) # type: ignore\n",
    "\n",
    "    print('Creating the thread...')\n",
    "    assistant, thread_id = assistant.make_thread()\n",
    "\n",
    "    print('Adding the prompt...')\n",
    "    assistant, prompt_msg = assistant.add_message(prompt)\n",
    "\n",
    "    print('Executing the thread...')\n",
    "    assistant, new_msgs = assistant.run_thread()\n",
    "\n",
    "    print('Tee up the AI to run the code...')\n",
    "    assistant, next_step_msg = assistant.add_message(\"use the run_python function to run the python you have just generated.\")\n",
    "\n",
    "    print('Run the python code and generate the file...')\n",
    "    assistant, new_msgs = assistant.run_thread(toolbox=[ai_tools[0].name]) # this is a function that executes a string of python passed into it\n",
    "\n",
    "    return 'finished'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n",
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "Setting the instructions...\n",
      "set_instructions()\n",
      "Equipping the assistant...\n",
      "equip_tools([TurboTool(name='run_python', config={'type': 'function', 'function': {'name': 'run_python', 'description': 'This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.', 'parameters': {'type': 'object', 'properties': {'pythonScript': {'type': 'string'}}}}}, function=<function run_python at 0x1103243a0>)], False)\n",
      "Creating the thread...\n",
      "make_thread()\n",
      "Adding the prompt...\n",
      "add_message( Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_0.csv\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \n",
      "\n",
      " TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed in the previous 7 days. \n",
      "- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\n",
      "- TIP 3: You should NOT use a GROUP BY in your SQL statement to measure reach \n",
      "\n",
      "The data you need to execute the task can be found in a postgres database with TABLE_DEFINITIONS described below.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE campaign.universe (userid integer, weight integer, gender text);\n",
      " Sample Data for universe:\n",
      "|    |   userid |   weight | gender   |\n",
      "|---:|---------:|---------:|:---------|\n",
      "|  0 |        1 |        1 | F        |\n",
      "|  1 |        2 |        1 | M        |\n",
      "|  2 |        3 |        1 | M        |\n",
      "|  3 |        4 |        1 | M        |\n",
      "|  4 |        5 |        1 | F        |\n",
      "|  5 |        6 |        1 | F        |\n",
      "|  6 |        7 |        1 | M        |\n",
      "|  7 |        8 |        1 | M        |\n",
      "|  8 |        9 |        1 | M        |\n",
      "|  9 |       10 |        1 | M        |\n",
      "\n",
      "CREATE TABLE campaign.conversions (conversionid integer, userid integer, conversindate date, conversionamt double precision);\n",
      " Sample Data for conversions:\n",
      "|    |   conversionid |   userid | conversindate   |   conversionamt |\n",
      "|---:|---------------:|---------:|:----------------|----------------:|\n",
      "|  0 |              1 |     7281 | 2023-08-12      |       16.6145   |\n",
      "|  1 |              2 |     8138 | 2023-08-07      |       11.4012   |\n",
      "|  2 |              3 |     2510 | 2023-08-10      |       18.8951   |\n",
      "|  3 |              4 |     9444 | 2023-09-25      |        0.108674 |\n",
      "|  4 |              5 |     9450 | 2023-08-18      |       13.6739   |\n",
      "|  5 |              6 |     6683 | 2023-08-25      |       17.0937   |\n",
      "|  6 |              7 |     3964 | 2023-10-27      |        2.09294  |\n",
      "|  7 |              8 |     8710 | 2023-09-07      |        2.36097  |\n",
      "|  8 |              9 |      311 | 2023-08-20      |        0.45382  |\n",
      "|  9 |             10 |     7562 | 2023-08-06      |        4.21386  |\n",
      "\n",
      "CREATE TABLE campaign.exposures (exposureid integer, userid integer, exposuredate date, propertyname text, creativename text, daypart text, exposuretype text);\n",
      " Sample Data for exposures:\n",
      "|    |   exposureid |   userid | exposuredate   | propertyname        | creativename                | daypart         | exposuretype   |\n",
      "|---:|-------------:|---------:|:---------------|:--------------------|:----------------------------|:----------------|:---------------|\n",
      "|  0 |            1 |     8237 | 2023-09-20     | Showtime            | Bobs Burger Bash            | Daytime         | DigitalVideo   |\n",
      "|  1 |            2 |     6231 | 2023-08-04     | NBCSN               | Bobs Best Burgers           | Late Night      | LinearTV       |\n",
      "|  2 |            3 |     3712 | 2023-08-25     | Cinemax             | Bobs Best Burgers           | Early Fringe    | StreamingApp   |\n",
      "|  3 |            4 |     5832 | 2023-09-16     | Discovery Channel   | Bite into Bobs              | Late Night      | LinearTV       |\n",
      "|  4 |            5 |      144 | 2023-09-26     | Lifetime            | Bobs Best Burgers           | Daytime         | SocialMedia    |\n",
      "|  5 |            6 |     6263 | 2023-09-15     | Syfy                | Delicious Burgers On-the-Go | Daytime         | SocialMedia    |\n",
      "|  6 |            7 |     8011 | 2023-08-29     | Smithsonian Channel | Bobs Flippin Good Burgers   | Early Fringe    | StreamingApp   |\n",
      "|  7 |            8 |     9422 | 2023-08-24     | Hallmark Channel    | Bobs Flippin Good Burgers   | Afternoon Drive | DigitalVideo   |\n",
      "|  8 |            9 |     8569 | 2023-09-05     | Lifetime            | Bobs Flippin Good Burgers   | Prime Time      | StreamingApp   |\n",
      "|  9 |           10 |      399 | 2023-09-30     | National Geographic | Bobs Flippin Good Burgers   | Morning Drive   | StreamingApp   |\n",
      "\n",
      " Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\n",
      "host: RENDER_PG_HOST\n",
      "database: RENDER_PG_NAME\n",
      "username: RENDER_PG_USER\n",
      "password: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.)\n",
      "Executing the thread...\n",
      "run_thread(None)\n",
      "Tee up the AI to run the code...\n",
      "add_message(use the run_python function to run the python you have just generated.)\n",
      "Run the python code and generate the file...\n",
      "run_thread(['run_python'])\n",
      "run_thread() Calling run_python({'pythonScript': 'import os\\nimport csv\\nimport psycopg2\\nfrom datetime import datetime, timedelta\\n\\n# Database connection details from environment variables\\ndb_host = os.getenv(\\'RENDER_PG_HOST\\')\\ndb_name = os.getenv(\\'RENDER_PG_NAME\\')\\ndb_user = os.getenv(\\'RENDER_PG_USER\\')\\ndb_password = os.getenv(\\'RENDER_PG_PASSWORD\\')\\n\\n# Function to connect to the Postgres database\\ndef connect_to_db():\\n    return psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\\n\\n# Calculate reach for each day within the specified date range\\ndef calculate_daily_reach(start_date, end_date):\\n    daily_reach = []\\n    with connect_to_db() as conn:\\n        with conn.cursor() as cursor:\\n            current_date = start_date\\n            while current_date <= end_date:\\n                # Define window of 7-day lookback, not including the current day\\n                window_start = current_date - timedelta(days=6)\\n                window_end = current_date - timedelta(days=1)\\n\\n                # SQL query to find distinct user count in the last 7 days (6 days plus today)\\n                query = \"\"\"\\n                SELECT COUNT(DISTINCT userid) AS reach\\n                FROM campaign.exposures\\n                WHERE exposuredate BETWEEN %s AND %s;\\n                \"\"\"\\n                cursor.execute(query, (window_start, window_end))\\n\\n                # Extract the reach count from the query results\\n                reach_count = cursor.fetchone()[0]\\n                daily_reach.append({\\'date\\': current_date.strftime(\\'%Y-%m-%d\\'), \\'reach\\': reach_count})\\n\\n                # Move to the next day\\n                current_date += timedelta(days=1)\\n\\n    return daily_reach\\n\\n# Write results to a CSV file\\ndef write_to_csv(file_name, data):\\n    with open(file_name, mode=\\'w\\', newline=\\'\\') as file:\\n        writer = csv.DictWriter(file, fieldnames=[\\'date\\', \\'reach\\'])\\n        writer.writeheader()\\n        for row in data:\\n            writer.writerow(row)\\n\\n# Main script execution\\nif __name__ == \\'__main__\\':\\n    start_date = datetime(2023, 8, 1)\\n    end_date = datetime(2023, 9, 1)\\n    daily_reach_data = calculate_daily_reach(start_date, end_date)\\n    output_file_name = \\'ANSWER_0.csv\\'\\n    write_to_csv(output_file_name, daily_reach_data)\\n    print(f\\'Data written to {output_file_name}\\')'})\n",
      "Success!\n",
      "Starting iteration 1...\n",
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "Setting the instructions...\n",
      "set_instructions()\n",
      "Equipping the assistant...\n",
      "equip_tools([TurboTool(name='run_python', config={'type': 'function', 'function': {'name': 'run_python', 'description': 'This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.', 'parameters': {'type': 'object', 'properties': {'pythonScript': {'type': 'string'}}}}}, function=<function run_python at 0x1103243a0>)], False)\n",
      "Creating the thread...\n",
      "make_thread()\n",
      "Adding the prompt...\n",
      "add_message( Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_1.csv\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \n",
      "\n",
      " TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed in the previous 7 days. \n",
      "- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\n",
      "- TIP 3: You should NOT use a GROUP BY in your SQL statement to measure reach \n",
      "\n",
      "The data you need to execute the task can be found in a postgres database with TABLE_DEFINITIONS described below.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE campaign.universe (userid integer, weight integer, gender text);\n",
      " Sample Data for universe:\n",
      "|    |   userid |   weight | gender   |\n",
      "|---:|---------:|---------:|:---------|\n",
      "|  0 |        1 |        1 | F        |\n",
      "|  1 |        2 |        1 | M        |\n",
      "|  2 |        3 |        1 | M        |\n",
      "|  3 |        4 |        1 | M        |\n",
      "|  4 |        5 |        1 | F        |\n",
      "|  5 |        6 |        1 | F        |\n",
      "|  6 |        7 |        1 | M        |\n",
      "|  7 |        8 |        1 | M        |\n",
      "|  8 |        9 |        1 | M        |\n",
      "|  9 |       10 |        1 | M        |\n",
      "\n",
      "CREATE TABLE campaign.conversions (conversionid integer, userid integer, conversindate date, conversionamt double precision);\n",
      " Sample Data for conversions:\n",
      "|    |   conversionid |   userid | conversindate   |   conversionamt |\n",
      "|---:|---------------:|---------:|:----------------|----------------:|\n",
      "|  0 |              1 |     7281 | 2023-08-12      |       16.6145   |\n",
      "|  1 |              2 |     8138 | 2023-08-07      |       11.4012   |\n",
      "|  2 |              3 |     2510 | 2023-08-10      |       18.8951   |\n",
      "|  3 |              4 |     9444 | 2023-09-25      |        0.108674 |\n",
      "|  4 |              5 |     9450 | 2023-08-18      |       13.6739   |\n",
      "|  5 |              6 |     6683 | 2023-08-25      |       17.0937   |\n",
      "|  6 |              7 |     3964 | 2023-10-27      |        2.09294  |\n",
      "|  7 |              8 |     8710 | 2023-09-07      |        2.36097  |\n",
      "|  8 |              9 |      311 | 2023-08-20      |        0.45382  |\n",
      "|  9 |             10 |     7562 | 2023-08-06      |        4.21386  |\n",
      "\n",
      "CREATE TABLE campaign.exposures (exposureid integer, userid integer, exposuredate date, propertyname text, creativename text, daypart text, exposuretype text);\n",
      " Sample Data for exposures:\n",
      "|    |   exposureid |   userid | exposuredate   | propertyname        | creativename                | daypart         | exposuretype   |\n",
      "|---:|-------------:|---------:|:---------------|:--------------------|:----------------------------|:----------------|:---------------|\n",
      "|  0 |            1 |     8237 | 2023-09-20     | Showtime            | Bobs Burger Bash            | Daytime         | DigitalVideo   |\n",
      "|  1 |            2 |     6231 | 2023-08-04     | NBCSN               | Bobs Best Burgers           | Late Night      | LinearTV       |\n",
      "|  2 |            3 |     3712 | 2023-08-25     | Cinemax             | Bobs Best Burgers           | Early Fringe    | StreamingApp   |\n",
      "|  3 |            4 |     5832 | 2023-09-16     | Discovery Channel   | Bite into Bobs              | Late Night      | LinearTV       |\n",
      "|  4 |            5 |      144 | 2023-09-26     | Lifetime            | Bobs Best Burgers           | Daytime         | SocialMedia    |\n",
      "|  5 |            6 |     6263 | 2023-09-15     | Syfy                | Delicious Burgers On-the-Go | Daytime         | SocialMedia    |\n",
      "|  6 |            7 |     8011 | 2023-08-29     | Smithsonian Channel | Bobs Flippin Good Burgers   | Early Fringe    | StreamingApp   |\n",
      "|  7 |            8 |     9422 | 2023-08-24     | Hallmark Channel    | Bobs Flippin Good Burgers   | Afternoon Drive | DigitalVideo   |\n",
      "|  8 |            9 |     8569 | 2023-09-05     | Lifetime            | Bobs Flippin Good Burgers   | Prime Time      | StreamingApp   |\n",
      "|  9 |           10 |      399 | 2023-09-30     | National Geographic | Bobs Flippin Good Burgers   | Morning Drive   | StreamingApp   |\n",
      "\n",
      " Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\n",
      "host: RENDER_PG_HOST\n",
      "database: RENDER_PG_NAME\n",
      "username: RENDER_PG_USER\n",
      "password: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.)\n",
      "Executing the thread...\n",
      "run_thread(None)\n",
      "Tee up the AI to run the code...\n",
      "add_message(use the run_python function to run the python you have just generated.)\n",
      "Run the python code and generate the file...\n",
      "run_thread(['run_python'])\n",
      "run_thread() Calling run_python({'pythonScript': 'import os\\nimport psycopg2\\nimport csv\\nfrom datetime import datetime, timedelta\\n\\n# Environment variables\\nhost = os.environ.get(\\'RENDER_PG_HOST\\')\\ndatabase = os.environ.get(\\'RENDER_PG_NAME\\')\\nusername = os.environ.get(\\'RENDER_PG_USER\\')\\npassword = os.environ.get(\\'RENDER_PG_PASSWORD\\')\\n\\n# Connect to the database\\nconn = psycopg2.connect(\\n    dbname=database,\\n    user=username,\\n    password=password,\\n    host=host\\n)\\n\\n# Create a cursor\\ncursor = conn.cursor()\\n\\n# Define the date range for the report\\nstart_date = datetime(2023, 8, 1)\\nend_date = datetime(2023, 9, 1)\\n\\n# CSV file\\ncsv_filename = \\'ANSWER_1.csv\\'\\n\\n# Open CSV file\\nwith open(csv_filename, mode=\\'w\\', newline=\\'\\') as csv_file:\\n    writer = csv.writer(csv_file)\\n    # Write the header\\n    writer.writerow([\\'date\\', \\'reach\\'])\\n\\n    # Query and write results for each day\\n    for n in range((end_date - start_date).days + 1):\\n        day = start_date + timedelta(days=n)\\n        day_minus_6 = day - timedelta(days=6)\\n        \\n        # SQL query to calculate daily reach with 7-day lookback window\\n        sql_query = f\\'\\'\\'\\n        SELECT COUNT(DISTINCT userid)\\n        FROM campaign.exposures\\n        WHERE exposuredate BETWEEN \\'{day_minus_6.strftime(\"%Y-%m-%d\")}\\'\\n        AND \\'{day.strftime(\"%Y-%m-%d\")}\\'\\n        \\'\\'\\'\\n        cursor.execute(sql_query)\\n        reach_count = cursor.fetchone()[0]\\n        writer.writerow([day.strftime(\"%Y-%m-%d\"), reach_count])\\n\\n# Close the cursor and connection\\ncursor.close()\\nconn.close()\\n'})\n",
      "Success!\n",
      "Starting iteration 2...\n",
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "Setting the instructions...\n",
      "set_instructions()\n",
      "Equipping the assistant...\n",
      "equip_tools([TurboTool(name='run_python', config={'type': 'function', 'function': {'name': 'run_python', 'description': 'This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.', 'parameters': {'type': 'object', 'properties': {'pythonScript': {'type': 'string'}}}}}, function=<function run_python at 0x1103243a0>)], False)\n",
      "Creating the thread...\n",
      "make_thread()\n",
      "Adding the prompt...\n",
      "add_message( Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_2.csv\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \n",
      "\n",
      " TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed in the previous 7 days. \n",
      "- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\n",
      "- TIP 3: You should NOT use a GROUP BY in your SQL statement to measure reach \n",
      "\n",
      "The data you need to execute the task can be found in a postgres database with TABLE_DEFINITIONS described below.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE campaign.universe (userid integer, weight integer, gender text);\n",
      " Sample Data for universe:\n",
      "|    |   userid |   weight | gender   |\n",
      "|---:|---------:|---------:|:---------|\n",
      "|  0 |        1 |        1 | F        |\n",
      "|  1 |        2 |        1 | M        |\n",
      "|  2 |        3 |        1 | M        |\n",
      "|  3 |        4 |        1 | M        |\n",
      "|  4 |        5 |        1 | F        |\n",
      "|  5 |        6 |        1 | F        |\n",
      "|  6 |        7 |        1 | M        |\n",
      "|  7 |        8 |        1 | M        |\n",
      "|  8 |        9 |        1 | M        |\n",
      "|  9 |       10 |        1 | M        |\n",
      "\n",
      "CREATE TABLE campaign.conversions (conversionid integer, userid integer, conversindate date, conversionamt double precision);\n",
      " Sample Data for conversions:\n",
      "|    |   conversionid |   userid | conversindate   |   conversionamt |\n",
      "|---:|---------------:|---------:|:----------------|----------------:|\n",
      "|  0 |              1 |     7281 | 2023-08-12      |       16.6145   |\n",
      "|  1 |              2 |     8138 | 2023-08-07      |       11.4012   |\n",
      "|  2 |              3 |     2510 | 2023-08-10      |       18.8951   |\n",
      "|  3 |              4 |     9444 | 2023-09-25      |        0.108674 |\n",
      "|  4 |              5 |     9450 | 2023-08-18      |       13.6739   |\n",
      "|  5 |              6 |     6683 | 2023-08-25      |       17.0937   |\n",
      "|  6 |              7 |     3964 | 2023-10-27      |        2.09294  |\n",
      "|  7 |              8 |     8710 | 2023-09-07      |        2.36097  |\n",
      "|  8 |              9 |      311 | 2023-08-20      |        0.45382  |\n",
      "|  9 |             10 |     7562 | 2023-08-06      |        4.21386  |\n",
      "\n",
      "CREATE TABLE campaign.exposures (exposureid integer, userid integer, exposuredate date, propertyname text, creativename text, daypart text, exposuretype text);\n",
      " Sample Data for exposures:\n",
      "|    |   exposureid |   userid | exposuredate   | propertyname        | creativename                | daypart         | exposuretype   |\n",
      "|---:|-------------:|---------:|:---------------|:--------------------|:----------------------------|:----------------|:---------------|\n",
      "|  0 |            1 |     8237 | 2023-09-20     | Showtime            | Bobs Burger Bash            | Daytime         | DigitalVideo   |\n",
      "|  1 |            2 |     6231 | 2023-08-04     | NBCSN               | Bobs Best Burgers           | Late Night      | LinearTV       |\n",
      "|  2 |            3 |     3712 | 2023-08-25     | Cinemax             | Bobs Best Burgers           | Early Fringe    | StreamingApp   |\n",
      "|  3 |            4 |     5832 | 2023-09-16     | Discovery Channel   | Bite into Bobs              | Late Night      | LinearTV       |\n",
      "|  4 |            5 |      144 | 2023-09-26     | Lifetime            | Bobs Best Burgers           | Daytime         | SocialMedia    |\n",
      "|  5 |            6 |     6263 | 2023-09-15     | Syfy                | Delicious Burgers On-the-Go | Daytime         | SocialMedia    |\n",
      "|  6 |            7 |     8011 | 2023-08-29     | Smithsonian Channel | Bobs Flippin Good Burgers   | Early Fringe    | StreamingApp   |\n",
      "|  7 |            8 |     9422 | 2023-08-24     | Hallmark Channel    | Bobs Flippin Good Burgers   | Afternoon Drive | DigitalVideo   |\n",
      "|  8 |            9 |     8569 | 2023-09-05     | Lifetime            | Bobs Flippin Good Burgers   | Prime Time      | StreamingApp   |\n",
      "|  9 |           10 |      399 | 2023-09-30     | National Geographic | Bobs Flippin Good Burgers   | Morning Drive   | StreamingApp   |\n",
      "\n",
      " Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\n",
      "host: RENDER_PG_HOST\n",
      "database: RENDER_PG_NAME\n",
      "username: RENDER_PG_USER\n",
      "password: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.)\n",
      "Executing the thread...\n",
      "run_thread(None)\n",
      "Tee up the AI to run the code...\n",
      "add_message(use the run_python function to run the python you have just generated.)\n",
      "Run the python code and generate the file...\n",
      "run_thread(['run_python'])\n",
      "run_thread() Calling run_python({'pythonScript': 'import os\\nimport psycopg2\\nimport csv\\nfrom datetime import datetime, timedelta\\n\\n# Environment variables for database connection\\nhost = os.getenv(\\'RENDER_PG_HOST\\')\\ndatabase = os.getenv(\\'RENDER_PG_NAME\\')\\nusername = os.getenv(\\'RENDER_PG_USER\\')\\npassword = os.getenv(\\'RENDER_PG_PASSWORD\\')\\n\\n# Database connection string\\nconn_string = f\"host={host} dbname={database} user={username} password={password}\"\\n\\n# Establish a connection to the database\\nconn = psycopg2.connect(conn_string)\\ncursor = conn.cursor()\\n\\n# Prepare the SQL query according to the requirements\\nquery = \"\"\"\\nSELECT exposuredate::date, COUNT(DISTINCT userid) as reach\\nFROM campaign.exposures\\nWHERE exposuredate BETWEEN %(start_date)s AND %(end_date)s\\nAND userid IN (\\n    SELECT DISTINCT userid\\n    FROM campaign.exposures\\n    WHERE exposuredate BETWEEN exposuredate - INTERVAL \\'6 days\\' AND exposuredate\\n)\\nGROUP BY exposuredate::date\\nORDER BY exposuredate::date;\\n\"\"\"\\n\\n# Start and end dates for the required daily campaign reach report\\nstart_date = datetime(2023, 8, 1)\\nend_date = datetime(2023, 9, 1)\\n\\n# Execute the query\\ncursor.execute(query, {\"start_date\": start_date, \"end_date\": end_date})\\n\\n# Fetch the results\\nresults = cursor.fetchall()\\n\\n# Write the results to a CSV file\\nwith open(\\'ANSWER_2.csv\\', \\'w\\', newline=\\'\\') as csvfile:\\n    fieldnames = [\\'exposuredate\\', \\'reach\\']\\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n    \\n    writer.writeheader()\\n    for row in results:\\n        writer.writerow({\\'exposuredate\\': row[0], \\'reach\\': row[1]})\\n\\n# Clean up\\ncursor.close()\\nconn.close()'})\n",
      "Success!\n",
      "Starting iteration 3...\n",
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "Setting the instructions...\n",
      "set_instructions()\n",
      "Equipping the assistant...\n",
      "equip_tools([TurboTool(name='run_python', config={'type': 'function', 'function': {'name': 'run_python', 'description': 'This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.', 'parameters': {'type': 'object', 'properties': {'pythonScript': {'type': 'string'}}}}}, function=<function run_python at 0x1103243a0>)], False)\n",
      "Creating the thread...\n",
      "make_thread()\n",
      "Adding the prompt...\n",
      "add_message( Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_3.csv\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \n",
      "\n",
      " TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed in the previous 7 days. \n",
      "- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\n",
      "- TIP 3: You should NOT use a GROUP BY in your SQL statement to measure reach \n",
      "\n",
      "The data you need to execute the task can be found in a postgres database with TABLE_DEFINITIONS described below.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE campaign.universe (userid integer, weight integer, gender text);\n",
      " Sample Data for universe:\n",
      "|    |   userid |   weight | gender   |\n",
      "|---:|---------:|---------:|:---------|\n",
      "|  0 |        1 |        1 | F        |\n",
      "|  1 |        2 |        1 | M        |\n",
      "|  2 |        3 |        1 | M        |\n",
      "|  3 |        4 |        1 | M        |\n",
      "|  4 |        5 |        1 | F        |\n",
      "|  5 |        6 |        1 | F        |\n",
      "|  6 |        7 |        1 | M        |\n",
      "|  7 |        8 |        1 | M        |\n",
      "|  8 |        9 |        1 | M        |\n",
      "|  9 |       10 |        1 | M        |\n",
      "\n",
      "CREATE TABLE campaign.conversions (conversionid integer, userid integer, conversindate date, conversionamt double precision);\n",
      " Sample Data for conversions:\n",
      "|    |   conversionid |   userid | conversindate   |   conversionamt |\n",
      "|---:|---------------:|---------:|:----------------|----------------:|\n",
      "|  0 |              1 |     7281 | 2023-08-12      |       16.6145   |\n",
      "|  1 |              2 |     8138 | 2023-08-07      |       11.4012   |\n",
      "|  2 |              3 |     2510 | 2023-08-10      |       18.8951   |\n",
      "|  3 |              4 |     9444 | 2023-09-25      |        0.108674 |\n",
      "|  4 |              5 |     9450 | 2023-08-18      |       13.6739   |\n",
      "|  5 |              6 |     6683 | 2023-08-25      |       17.0937   |\n",
      "|  6 |              7 |     3964 | 2023-10-27      |        2.09294  |\n",
      "|  7 |              8 |     8710 | 2023-09-07      |        2.36097  |\n",
      "|  8 |              9 |      311 | 2023-08-20      |        0.45382  |\n",
      "|  9 |             10 |     7562 | 2023-08-06      |        4.21386  |\n",
      "\n",
      "CREATE TABLE campaign.exposures (exposureid integer, userid integer, exposuredate date, propertyname text, creativename text, daypart text, exposuretype text);\n",
      " Sample Data for exposures:\n",
      "|    |   exposureid |   userid | exposuredate   | propertyname        | creativename                | daypart         | exposuretype   |\n",
      "|---:|-------------:|---------:|:---------------|:--------------------|:----------------------------|:----------------|:---------------|\n",
      "|  0 |            1 |     8237 | 2023-09-20     | Showtime            | Bobs Burger Bash            | Daytime         | DigitalVideo   |\n",
      "|  1 |            2 |     6231 | 2023-08-04     | NBCSN               | Bobs Best Burgers           | Late Night      | LinearTV       |\n",
      "|  2 |            3 |     3712 | 2023-08-25     | Cinemax             | Bobs Best Burgers           | Early Fringe    | StreamingApp   |\n",
      "|  3 |            4 |     5832 | 2023-09-16     | Discovery Channel   | Bite into Bobs              | Late Night      | LinearTV       |\n",
      "|  4 |            5 |      144 | 2023-09-26     | Lifetime            | Bobs Best Burgers           | Daytime         | SocialMedia    |\n",
      "|  5 |            6 |     6263 | 2023-09-15     | Syfy                | Delicious Burgers On-the-Go | Daytime         | SocialMedia    |\n",
      "|  6 |            7 |     8011 | 2023-08-29     | Smithsonian Channel | Bobs Flippin Good Burgers   | Early Fringe    | StreamingApp   |\n",
      "|  7 |            8 |     9422 | 2023-08-24     | Hallmark Channel    | Bobs Flippin Good Burgers   | Afternoon Drive | DigitalVideo   |\n",
      "|  8 |            9 |     8569 | 2023-09-05     | Lifetime            | Bobs Flippin Good Burgers   | Prime Time      | StreamingApp   |\n",
      "|  9 |           10 |      399 | 2023-09-30     | National Geographic | Bobs Flippin Good Burgers   | Morning Drive   | StreamingApp   |\n",
      "\n",
      " Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\n",
      "host: RENDER_PG_HOST\n",
      "database: RENDER_PG_NAME\n",
      "username: RENDER_PG_USER\n",
      "password: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.)\n",
      "Executing the thread...\n",
      "run_thread(None)\n",
      "Tee up the AI to run the code...\n",
      "add_message(use the run_python function to run the python you have just generated.)\n",
      "Run the python code and generate the file...\n",
      "run_thread(['run_python'])\n",
      "run_thread() Calling run_python({'pythonScript': 'import os\\nimport psycopg2\\nimport csv\\nfrom datetime import datetime, timedelta\\n\\n# Environment variables for database connection\\npg_host = os.environ.get(\\'RENDER_PG_HOST\\')\\npg_database = os.environ.get(\\'RENDER_PG_NAME\\')\\npg_user = os.environ.get(\\'RENDER_PG_USER\\')\\npg_password = os.environ.get(\\'RENDER_PG_PASSWORD\\')\\n\\n# Dates for the specified range\\nstart_date = datetime(2023, 8, 1)\\nend_date = datetime(2023, 9, 1)\\n\\n# Connect to the database\\nconn = psycopg2.connect(\\n    host=pg_host,\\n    database=pg_database,\\n    user=pg_user,\\n    password=pg_password\\n)\\n\\ncur = conn.cursor()\\n\\n# Calculate range of the lookback window (Tip 2 suggests 6 days)\\nlookback_days = 6\\n\\n# Prepare CSV file to write the results\\nwith open(\\'ANSWER_3.csv\\', \\'w\\', newline=\\'\\') as csvfile:\\n    writer = csv.writer(csvfile)\\n    writer.writerow([\\'Date\\', \\'Reach\\'])\\n\\n    # Calculate reach for each day within the specified period\\n    for single_date in (start_date + timedelta(n) for n in range((end_date - start_date).days + 1)):\\n        lookback_start = single_date - timedelta(days=lookback_days)\\n        query = \"\"\"\\n            SELECT COUNT(DISTINCT e.userid) AS reach\\n            FROM campaign.exposures e\\n            WHERE e.exposuredate BETWEEN %s AND %s\\n        \"\"\"\\n        cur.execute(query, (lookback_start, single_date))\\n        reach = cur.fetchone()[0]\\n        writer.writerow([single_date.strftime(\\'%Y-%m-%d\\'), reach])\\n\\n# Close the cursor and database connection\\ncur.close()\\nconn.close()\\n'})\n",
      "Success!\n",
      "Starting iteration 4...\n",
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "Setting the instructions...\n",
      "set_instructions()\n",
      "Equipping the assistant...\n",
      "equip_tools([TurboTool(name='run_python', config={'type': 'function', 'function': {'name': 'run_python', 'description': 'This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.', 'parameters': {'type': 'object', 'properties': {'pythonScript': {'type': 'string'}}}}}, function=<function run_python at 0x1103243a0>)], False)\n",
      "Creating the thread...\n",
      "make_thread()\n",
      "Adding the prompt...\n",
      "add_message( Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_4.csv\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \n",
      "\n",
      " TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed in the previous 7 days. \n",
      "- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\n",
      "- TIP 3: You should NOT use a GROUP BY in your SQL statement to measure reach \n",
      "\n",
      "The data you need to execute the task can be found in a postgres database with TABLE_DEFINITIONS described below.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE campaign.universe (userid integer, weight integer, gender text);\n",
      " Sample Data for universe:\n",
      "|    |   userid |   weight | gender   |\n",
      "|---:|---------:|---------:|:---------|\n",
      "|  0 |        1 |        1 | F        |\n",
      "|  1 |        2 |        1 | M        |\n",
      "|  2 |        3 |        1 | M        |\n",
      "|  3 |        4 |        1 | M        |\n",
      "|  4 |        5 |        1 | F        |\n",
      "|  5 |        6 |        1 | F        |\n",
      "|  6 |        7 |        1 | M        |\n",
      "|  7 |        8 |        1 | M        |\n",
      "|  8 |        9 |        1 | M        |\n",
      "|  9 |       10 |        1 | M        |\n",
      "\n",
      "CREATE TABLE campaign.conversions (conversionid integer, userid integer, conversindate date, conversionamt double precision);\n",
      " Sample Data for conversions:\n",
      "|    |   conversionid |   userid | conversindate   |   conversionamt |\n",
      "|---:|---------------:|---------:|:----------------|----------------:|\n",
      "|  0 |              1 |     7281 | 2023-08-12      |       16.6145   |\n",
      "|  1 |              2 |     8138 | 2023-08-07      |       11.4012   |\n",
      "|  2 |              3 |     2510 | 2023-08-10      |       18.8951   |\n",
      "|  3 |              4 |     9444 | 2023-09-25      |        0.108674 |\n",
      "|  4 |              5 |     9450 | 2023-08-18      |       13.6739   |\n",
      "|  5 |              6 |     6683 | 2023-08-25      |       17.0937   |\n",
      "|  6 |              7 |     3964 | 2023-10-27      |        2.09294  |\n",
      "|  7 |              8 |     8710 | 2023-09-07      |        2.36097  |\n",
      "|  8 |              9 |      311 | 2023-08-20      |        0.45382  |\n",
      "|  9 |             10 |     7562 | 2023-08-06      |        4.21386  |\n",
      "\n",
      "CREATE TABLE campaign.exposures (exposureid integer, userid integer, exposuredate date, propertyname text, creativename text, daypart text, exposuretype text);\n",
      " Sample Data for exposures:\n",
      "|    |   exposureid |   userid | exposuredate   | propertyname        | creativename                | daypart         | exposuretype   |\n",
      "|---:|-------------:|---------:|:---------------|:--------------------|:----------------------------|:----------------|:---------------|\n",
      "|  0 |            1 |     8237 | 2023-09-20     | Showtime            | Bobs Burger Bash            | Daytime         | DigitalVideo   |\n",
      "|  1 |            2 |     6231 | 2023-08-04     | NBCSN               | Bobs Best Burgers           | Late Night      | LinearTV       |\n",
      "|  2 |            3 |     3712 | 2023-08-25     | Cinemax             | Bobs Best Burgers           | Early Fringe    | StreamingApp   |\n",
      "|  3 |            4 |     5832 | 2023-09-16     | Discovery Channel   | Bite into Bobs              | Late Night      | LinearTV       |\n",
      "|  4 |            5 |      144 | 2023-09-26     | Lifetime            | Bobs Best Burgers           | Daytime         | SocialMedia    |\n",
      "|  5 |            6 |     6263 | 2023-09-15     | Syfy                | Delicious Burgers On-the-Go | Daytime         | SocialMedia    |\n",
      "|  6 |            7 |     8011 | 2023-08-29     | Smithsonian Channel | Bobs Flippin Good Burgers   | Early Fringe    | StreamingApp   |\n",
      "|  7 |            8 |     9422 | 2023-08-24     | Hallmark Channel    | Bobs Flippin Good Burgers   | Afternoon Drive | DigitalVideo   |\n",
      "|  8 |            9 |     8569 | 2023-09-05     | Lifetime            | Bobs Flippin Good Burgers   | Prime Time      | StreamingApp   |\n",
      "|  9 |           10 |      399 | 2023-09-30     | National Geographic | Bobs Flippin Good Burgers   | Morning Drive   | StreamingApp   |\n",
      "\n",
      " Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\n",
      "host: RENDER_PG_HOST\n",
      "database: RENDER_PG_NAME\n",
      "username: RENDER_PG_USER\n",
      "password: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.)\n",
      "Executing the thread...\n",
      "run_thread(None)\n",
      "Tee up the AI to run the code...\n",
      "add_message(use the run_python function to run the python you have just generated.)\n",
      "Run the python code and generate the file...\n",
      "run_thread(['run_python'])\n",
      "run_thread() Calling run_python({'pythonScript': 'import os\\nimport psycopg2\\nimport csv\\nfrom datetime import date, timedelta\\n\\n# Environment variables\\nhost = os.getenv(\"RENDER_PG_HOST\")\\ndatabase = os.getenv(\"RENDER_PG_NAME\")\\nusername = os.getenv(\"RENDER_PG_USER\")\\npassword = os.getenv(\"RENDER_PG_PASSWORD\")\\n\\n# Connect to the PostgreSQL database\\nconn = psycopg2.connect(host=host, database=database, user=username, password=password)\\ncur = conn.cursor()\\n\\n# Define the date range\\nstart_date = date(2023, 8, 1)\\nend_date = date(2023, 9, 1)\\n\\n# Prepare the CSV file\\nwith open(\\'ANSWER_4.csv\\', \\'w\\', newline=\\'\\') as csvfile:\\n    fieldnames = [\\'date\\', \\'reach\\']\\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n    writer.writeheader()\\n\\n    # Calculate daily reach for each day in the specified date range\\n    for single_date in (start_date + timedelta(n) for n in range((end_date - start_date).days)):\\n        # Calculate the 7-day lookback window\\n        lookback_start = single_date - timedelta(days=6)\\n        \\n        # SQL query to count distinct users with exposure in the 7-day lookback window\\n        query = \"\"\"\\n        SELECT COUNT(DISTINCT e.userid)\\n        FROM campaign.exposures e\\n        WHERE e.exposuredate BETWEEN %s AND %s;\\n        \"\"\"\\n        \\n        # Execute the query\\n        cur.execute(query, (lookback_start, single_date))\\n        reach = cur.fetchone()[0]\\n        \\n        # Write to CSV\\n        writer.writerow({\\'date\\': single_date, \\'reach\\': reach})\\n\\n# Close the connection\\ncur.close()\\nconn.close()\\n'})\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# first prompt: What is the total reach of the campaign?\n",
    "# second prompt: How many users saw an ad?\n",
    "# third prompt: What is the total reach of the campaign?\\n Here is a hint you can use to help answer the QUESTION. The total reach of an advertising campaign is determined by counting the number of distinct users who saw an ad. \n",
    "\n",
    "# first prompt: Please report daily campaign reach where reach for a given day is defined to be total number of users who were exposed in the previous 7 day window. Perform the calculation for each day from August 1 2023 to September 1 2023\n",
    "# second prompt: Please calculate daily campaign reach. Use a 7 day lookback window when determining the reach for a given day. Perform the calculation for each day from August 1 2023 to September 1 2023\n",
    "# third prompt: Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \\n\\n TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed anytime during the previous 7 days.\\n- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\\n\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "successfulRuns = 0\n",
    "badRuns = 0\n",
    "for ii in np.arange(5):\n",
    "    print(f'Starting iteration {str(ii)}...')\n",
    "    try:\n",
    "        aiRun = runAI('''Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \\n\\n TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed anytime during the previous 7 days.\\n- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\\n''', ii=ii)\n",
    "        if aiRun == 'finished':\n",
    "            successfulRuns += 1\n",
    "            print('Success!')\n",
    "            results.append(pd.read_csv(f'ANSWER_{str(ii)}.csv'))\n",
    "        else:\n",
    "            print('Failure!')\n",
    "            badRuns += 1\n",
    "    except:\n",
    "        print('Failure!')\n",
    "        badRuns += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Prompt: What is the total reach of the campaign?\n",
    "\n",
    "Good answer:\n",
    "SELECT SUM(weight) as total_reach\n",
    "FROM campaign.universe uni\n",
    "INNER JOIN campaign.exposures exp ON uni.userid = exp.userid\n",
    "\n",
    "Fine answer:\n",
    "SELECT COUNT(DISTINCT userid) FROM campaign.exposures\n",
    "\n",
    "\n",
    "Bad answer:\n",
    "SELECT SUM(weight) AS total_reach\n",
    "FROM campaign.universe\n",
    "\n",
    "V bad answer:\n",
    "SELECT SUM(DISTINCT weight) FROM campaign.universe u JOIN campaign.exposures e ON u.userid = e.userid\n",
    "\n",
    "RESULTS:\n",
    " - Successful runs: 20\n",
    " - Bad runs: 0\n",
    "\n",
    " - Correct answer: 4\n",
    " - Other answers: 25K - 11, 100K - 4, 1 - 1\n",
    " \n",
    "\"\"\"\n",
    "print(successfulRuns, badRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Prompt: How many users saw an ad?\n",
    "\n",
    "Good answer:\n",
    "SELECT COUNT(DISTINCT userid) FROM campaign.exposures;\n",
    "\n",
    "\n",
    "RESULTS:\n",
    " - Successful runs: 19\n",
    " - Bad runs: 1\n",
    "\n",
    " - Correct answer: 19\n",
    " - Other answers: \n",
    " \n",
    "\"\"\"\n",
    "print(successfulRuns, badRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prompt: What is the total reach of the campaign?\\n Here is a hint you can use to help answer the QUESTION. The total reach of an advertising campaign is determined by counting the number of distinct users who saw an ad.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
