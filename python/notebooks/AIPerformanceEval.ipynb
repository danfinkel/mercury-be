{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/danfinkel/github/mercury-be/\") \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import use\n",
    "from python.tools.turbo4 import Turbo4\n",
    "from python.tools.teachable import Teachable_Turbo4\n",
    "from python.tools.llmtypes import Chat, TurboTool\n",
    "from python.tools import rand\n",
    "from python.tools.instruments import AgentInstruments\n",
    "from python.tools.llm import add_cap_ref\n",
    "from python.tools.llm import getTableDefs\n",
    "from python.tools.helpers import run_python\n",
    "from python.tools.codeRepair import CodeRepair_Turbo4\n",
    "\n",
    "\n",
    "from typing import List, Callable\n",
    "import os\n",
    "import argparse\n",
    "import dotenv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danfinkel/github/mercury-be\n"
     ]
    }
   ],
   "source": [
    "# load .env vars\n",
    "tmp = os.getcwd()\n",
    "os.chdir(\"/Users/danfinkel/github/mercury-be/\")\n",
    "print(os.getcwd())\n",
    "os.environ.pop('OPENAI_API_KEY', None)\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# dotenv.load_dotenv(\"/Users/danfinkel/github/mercury-be/\")\n",
    "# print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "os.chdir(tmp)\n",
    "\n",
    "# check to make sure the important env vars are set\n",
    "assert os.environ.get(\"RENDER_PG_URL\"), \"POSTGRES_CONNECTION_URL not found in .env file\"\n",
    "assert os.environ.get(\"RENDER_PG_SCHEMA\"), \"DATABASE_SCHEMA not found in .env file\"\n",
    "\n",
    "# bring env variables into memory\n",
    "DB_URL = os.environ.get(\"RENDER_PG_URL\")\n",
    "DATABASE_SCHEMA = os.environ.get(\"RENDER_PG_SCHEMA\")\n",
    "POSTGRES_TABLE_DEFINITION_CAP_REF = \"TABLE_DEFINITIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table definitions for tables to be used for test\n",
    "table_definitions = getTableDefs(DB_URL, DATABASE_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_function_tool_config = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"run_python\",\n",
    "        \"description\": \"This is a function that executes a python script in a local environment. The variable pythonscript is a string that will be executed as a python script.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"pythonScript\": {\"type\": \"string\"}},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAI(raw_prompt: str, ii: int = 0) -> str:\n",
    "    \n",
    "    assistant_name = \"Turbo4_Testing\"\n",
    "    assistant = Turbo4()\n",
    "    \n",
    "    ai_tools = [\n",
    "        TurboTool(\"run_python\", custom_function_tool_config, run_python),\n",
    "    ]\n",
    "\n",
    "    prompt = add_cap_ref(\n",
    "    \"\", # type: ignore\n",
    "    f\"Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_{str(ii)}.csv\",\n",
    "    \"QUESTION:\",\n",
    "    raw_prompt\n",
    "    )\n",
    "\n",
    "    prompt = add_cap_ref(\n",
    "        prompt,  # type: ignore\n",
    "        f\"\\n\\nThe data you need to execute the task can be found in a postgres database with {POSTGRES_TABLE_DEFINITION_CAP_REF} described below.\", \n",
    "        POSTGRES_TABLE_DEFINITION_CAP_REF, \n",
    "        table_definitions # type: ignore\n",
    "    )    \n",
    "\n",
    "    prompt += '\\n\\n Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\\nhost: RENDER_PG_HOST\\ndatabase: RENDER_PG_NAME\\nusername: RENDER_PG_USER\\npassword: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.'\n",
    "\n",
    "    # Starting the assistant...\n",
    "    assistant, status_msg = assistant.get_or_create_assistant(assistant_name)\n",
    "\n",
    "    # Setting the instructions...\n",
    "    assistant, instruct_msg = assistant.set_instructions(\"You are an elite python developer that specializes in adtech. You generate the most concise and performant python scripts.\") # type: ignore\n",
    "\n",
    "    # Equipping the assistant...\n",
    "    # assistant = assistant.equip_tools(ai_tools, equip_on_assistant=False) # type: ignore\n",
    "\n",
    "    # Creating the thread...\n",
    "    assistant, thread_id = assistant.make_thread()\n",
    "\n",
    "    # Adding the prompt...\n",
    "    assistant, prompt_msg = assistant.add_message(prompt)\n",
    "\n",
    "    # Executing the thread...\n",
    "    assistant, new_msgs = assistant.run_thread()\n",
    "\n",
    "    return new_msgs[-1]\n",
    "\n",
    "    # print('Tee up the AI to run the code...')\n",
    "    # assistant, next_step_msg = assistant.add_message(\"use the run_python function to run the python you have just generated.\")\n",
    "\n",
    "    # print('Run the python code and generate the file...')\n",
    "    # assistant, new_msgs = assistant.run_thread(toolbox=[ai_tools[0].name]) # this is a function that executes a string of python passed into it\n",
    "\n",
    "    # return 'finished'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n",
      "get_or_create_assistant(Turbo4_Testing, gpt-4-1106-preview)\n",
      "set_instructions()\n",
      "make_thread()\n",
      "run_thread(None)\n",
      "Trying to run the script...ðŸ¤ž\n",
      "run python barfed ðŸ¤®\n",
      "Starting iteration 1...\n",
      "get_or_create_assistant(Turbo4_Testing, gpt-4-1106-preview)\n",
      "set_instructions()\n",
      "make_thread()\n",
      "run_thread(None)\n",
      "Trying to run the script...ðŸ¤ž\n",
      "Script Ran Successfully ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# first prompt: What is the total reach of the campaign?\n",
    "# second prompt: How many users saw an ad?\n",
    "# third prompt: What is the total reach of the campaign?\\n Here is a hint you can use to help answer the QUESTION. The total reach of an advertising campaign is determined by counting the number of distinct users who saw an ad. \n",
    "\n",
    "# first prompt: Please report daily campaign reach where reach for a given day is defined to be total number of users who were exposed in the previous 7 day window. Perform the calculation for each day from August 1 2023 to September 1 2023\n",
    "# second prompt: Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window.\n",
    "# third prompt: Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \\n\\n TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed to an ad anytime during the previous 7 days.\\n- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\\n\n",
    "\n",
    "# lift\n",
    "# prompt: Please report daily campaign lift from August 1 2023 to September 1 2023 with a 7 day causality window. \\n\\nTIPS:\\n- TIP 1: The lift for a given day is defined to be the difference between conversion rates of exposed users and unexposed users divided by the conversion rate of unexposed users.\\n- TIP 2: The conversion rate of exposed users is the ratio of users who converted within 7 days of exposure to the total count of users exposed on the measurement date\\n- TIP 3: The conversion rate of unexposed users is the ratio of users who were not exposed but converted within 7 days of the measurement date to the total count of unexposed users.\\n\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "successfulRuns = 0\n",
    "badRuns = 0\n",
    "badCode = []\n",
    "for ii in np.arange(2):\n",
    "    print(f'Starting iteration {str(ii)}...')\n",
    "    try:\n",
    "        aiRun = runAI('''Please report daily campaign lift from August 1 2023 to September 1 2023 with a 7 day causality window. \\n\\n- TIP: The lift for a given day is defined by the formula l = (Nex / Ne) / (Nux / Nu) - 1 where \\n- Nex = the number of users exposed on the measurement date and who converted within 7 days\\n- Ne = the number of users exposed\\n- Nux = the number of users who did not see an ad but who converted within 7 days of the measurement date\\n- Nu = the total number of users who did not see an ad\\n''', ii=ii)\n",
    "        pscript = aiRun.message.split('```python\\n')[1].split('```')[0] # type: ignore\n",
    "        try:\n",
    "            print('Trying to run the script...ðŸ¤ž')\n",
    "            run_status, result = run_python(pscript) # type: ignore\n",
    "            if run_status == 'success':\n",
    "                print('Script Ran Successfully ðŸ˜Ž')\n",
    "            elif run_status == 'error':\n",
    "                print('Script Failed ðŸ˜¥')\n",
    "\n",
    "                todd = CodeRepair_Turbo4(pscript, result)\n",
    "                updated_pscript = todd.repair_code().message.replace('```python\\n', '').replace('```', '')\n",
    "                print(updated_pscript)\n",
    "\n",
    "                run_status, result = run_python(updated_pscript) # type: ignore\n",
    "\n",
    "                if run_status == 'error':\n",
    "                    print('Script Repair Failed Again ðŸ˜¥')\n",
    "                    badRuns += 1\n",
    "                    badCode.append([pscript, updated_pscript])\n",
    "        except Exception as e: \n",
    "            print('run python barfed ðŸ¤®')\n",
    "            badRuns += 1        \n",
    "    except:\n",
    "        print('runAI failed ðŸ¤•')\n",
    "        print('Failure!')\n",
    "        badRuns += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi dad\n",
      "hi mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/danfinkel/github/mercury-be/python/notebooks/./pythonscript/runpython.py\", line 58, in <module>\n",
      "    cursor.execute(campaign_lift_query, {'start_date': start_date, 'end_date_plus_7': end_date_plus_7})\n",
      "KeyError: 'end_date'\n"
     ]
    }
   ],
   "source": [
    "print('hi dad')\n",
    "run_python(pscript)\n",
    "print('hi mom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Prompt: What is the total reach of the campaign?\n",
    "\n",
    "Good answer:\n",
    "SELECT SUM(weight) as total_reach\n",
    "FROM campaign.universe uni\n",
    "INNER JOIN campaign.exposures exp ON uni.userid = exp.userid\n",
    "\n",
    "Fine answer:\n",
    "SELECT COUNT(DISTINCT userid) FROM campaign.exposures\n",
    "\n",
    "\n",
    "Bad answer:\n",
    "SELECT SUM(weight) AS total_reach\n",
    "FROM campaign.universe\n",
    "\n",
    "V bad answer:\n",
    "SELECT SUM(DISTINCT weight) FROM campaign.universe u JOIN campaign.exposures e ON u.userid = e.userid\n",
    "\n",
    "RESULTS:\n",
    " - Successful runs: 20\n",
    " - Bad runs: 0\n",
    "\n",
    " - Correct answer: 4\n",
    " - Other answers: 25K - 11, 100K - 4, 1 - 1\n",
    " \n",
    "\"\"\"\n",
    "print(successfulRuns, badRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Prompt: How many users saw an ad?\n",
    "\n",
    "Good answer:\n",
    "SELECT COUNT(DISTINCT userid) FROM campaign.exposures;\n",
    "\n",
    "\n",
    "RESULTS:\n",
    " - Successful runs: 19\n",
    " - Bad runs: 1\n",
    "\n",
    " - Correct answer: 19\n",
    " - Other answers: \n",
    " \n",
    "\"\"\"\n",
    "print(successfulRuns, badRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prompt: What is the total reach of the campaign?\\n Here is a hint you can use to help answer the QUESTION. The total reach of an advertising campaign is determined by counting the number of distinct users who saw an ad.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the assistant...\n",
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-7B40K***************************************dFDZ. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mhost: RENDER_PG_HOST\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdatabase: RENDER_PG_NAME\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124musername: RENDER_PG_USER\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mpassword: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting the assistant...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m assistant, status_msg \u001b[38;5;241m=\u001b[39m \u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_assistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43massistant_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/mercury-be/python/tools/turbo4.py:169\u001b[0m, in \u001b[0;36mTurbo4.get_or_create_assistant\u001b[0;34m(self, name, model)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_or_create_assistant(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Retrieve the list of existing assistants\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m assistants: List[Assistant] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massistants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Check if an assistant with the given name already exists\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m assistant \u001b[38;5;129;01min\u001b[39;00m assistants:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/llm/lib/python3.9/site-packages/openai/resources/beta/assistants/assistants.py:270\u001b[0m, in \u001b[0;36mAssistants.list\u001b[0;34m(self, after, before, limit, order, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of assistants.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/assistants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSyncCursorPage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAssistant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mafter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbefore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbefore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlimit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43massistant_list_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssistantListParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAssistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/llm/lib/python3.9/site-packages/openai/_base_client.py:1137\u001b[0m, in \u001b[0;36mSyncAPIClient.get_api_list\u001b[0;34m(self, path, model, page, body, options, method)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api_list\u001b[39m(\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1128\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1135\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SyncPageT:\n\u001b[1;32m   1136\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m-> 1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_api_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/llm/lib/python3.9/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient._request_api_list\u001b[0;34m(self, model, page, options)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[1;32m    980\u001b[0m options\u001b[38;5;241m.\u001b[39mpost_parser \u001b[38;5;241m=\u001b[39m _parser\n\u001b[0;32m--> 982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/llm/lib/python3.9/site-packages/openai/_base_client.py:853\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    846\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    852\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/llm/lib/python3.9/site-packages/openai/_base_client.py:930\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m    928\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    933\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    934\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    938\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-7B40K***************************************dFDZ. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "raw_prompt = '''Please report daily campaign reach from August 1 2023 to September 1 2023 with a 7 day lookback window. \\n\\n TIPS:- TIP 1: The reach for a given day is defined to be count of distinct users who were exposed to an ad anytime during the previous 7 days.\\n- TIP 2: The BETWEEN SQL function is inclusive of its bounds. That means that when using BETWEEN for a 7 day window calculation you should use 6 days in the calculation.\\n''',\n",
    "assistant_name = \"Turbo4\"\n",
    "assistant = Turbo4()\n",
    "    \n",
    "ai_tools = [\n",
    "        TurboTool(\"run_python\", custom_function_tool_config, run_python),\n",
    "    ]\n",
    "\n",
    "prompt = add_cap_ref(\n",
    "    \"\", # type: ignore\n",
    "    f\"Write a python script that will print an answer the QUESTION. The script should write the answer to a csv file called ANSWER_{str(ii)}.csv\",\n",
    "    \"QUESTION:\",\n",
    "    raw_prompt\n",
    "    )\n",
    "\n",
    "prompt = add_cap_ref(\n",
    "        prompt,  # type: ignore\n",
    "        f\"\\n\\nThe data you need to execute the task can be found in a postgres database with {POSTGRES_TABLE_DEFINITION_CAP_REF} described below.\", \n",
    "        POSTGRES_TABLE_DEFINITION_CAP_REF, \n",
    "        table_definitions # type: ignore\n",
    "    )    \n",
    "\n",
    "prompt += '\\n\\n Finally, to connect to the postgres database with the datasets you need to answer this QUESTION you can use the following environmental variables:\\nhost: RENDER_PG_HOST\\ndatabase: RENDER_PG_NAME\\nusername: RENDER_PG_USER\\npassword: RENDER_PG_PASSWORD. You should assume these variables are in the environment of the python script and can be accessed with the os library.'\n",
    "\n",
    "print('Starting the assistant...')\n",
    "assistant, status_msg = assistant.get_or_create_assistant(assistant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedColumn",
     "evalue": "column c.conversiondate does not exist\nLINE 2: ...ISTINCT c.userid) AS Ne, COUNT(DISTINCT CASE WHEN c.conversi...\n                                                             ^\nHINT:  Perhaps you meant to reference the column \"c.conversindate\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# SQL to find Nex and Ne\u001b[39;00m\n\u001b[1;32m     31\u001b[0m sql_exposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mSELECT COUNT(DISTINCT c.userid) AS Ne, COUNT(DISTINCT CASE WHEN c.conversiondate < \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m THEN c.userid END) AS Nex\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mFROM campaign.exposures e\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mJOIN campaign.conversions c ON e.userid = c.userid\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124mWHERE e.exposuredate = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_exposed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcausality_end_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m Ne, Nex \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# SQL to find Nux and Nu\u001b[39;00m\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column c.conversiondate does not exist\nLINE 2: ...ISTINCT c.userid) AS Ne, COUNT(DISTINCT CASE WHEN c.conversi...\n                                                             ^\nHINT:  Perhaps you meant to reference the column \"c.conversindate\".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Environment variables for database connection\n",
    "host = os.environ.get('RENDER_PG_HOST')\n",
    "database = os.environ.get('RENDER_PG_NAME')\n",
    "username = os.environ.get('RENDER_PG_USER')\n",
    "password = os.environ.get('RENDER_PG_PASSWORD')\n",
    "\n",
    "# Database connection\n",
    "conn = psycopg2.connect(host=host, dbname=database, user=username, password=password)\n",
    "\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Dates for analysis\n",
    "start_date = datetime(2023, 8, 1)\n",
    "end_date = datetime(2023, 9, 1)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "# Data frame to store daily lift\n",
    "daily_lift_df = pd.DataFrame(columns=[\"date\", \"lift\"])\n",
    "\n",
    "while start_date < end_date:\n",
    "    # Calculate 7-day causality window end date\n",
    "    causality_end_date = start_date + timedelta(days=7)\n",
    "\n",
    "    # SQL to find Nex and Ne\n",
    "    sql_exposed = \"\"\"\n",
    "    SELECT COUNT(DISTINCT c.userid) AS Ne, COUNT(DISTINCT CASE WHEN c.conversiondate < %s THEN c.userid END) AS Nex\n",
    "    FROM campaign.exposures e\n",
    "    JOIN campaign.conversions c ON e.userid = c.userid\n",
    "    WHERE e.exposuredate = %s;\n",
    "    \"\"\"\n",
    "    cur.execute(sql_exposed, (causality_end_date, start_date))\n",
    "    Ne, Nex = cur.fetchone()\n",
    "\n",
    "    # SQL to find Nux and Nu\n",
    "    sql_unexposed = \"\"\"\n",
    "    SELECT COUNT(DISTINCT u.userid) AS Nu, COUNT(DISTINCT CASE WHEN c.conversiondate < %s THEN c.userid END) AS Nux\n",
    "    FROM campaign.universe u\n",
    "    LEFT JOIN campaign.exposures e ON u.userid = e.userid AND e.exposuredate = %s\n",
    "    LEFT JOIN campaign.conversions c ON u.userid = c.userid\n",
    "    WHERE e.userid IS NULL;\n",
    "    \"\"\"\n",
    "    cur.execute(sql_unexposed, (causality_end_date, start_date))\n",
    "    Nu, Nux = cur.fetchone()\n",
    "\n",
    "    # Calculate lift\n",
    "    lift = (Nex / Ne) / (Nux / Nu) - 1 if Ne > 0 and Nu > 0 else None\n",
    "\n",
    "    # Append to data frame\n",
    "    daily_lift_df = daily_lift_df.append({\"date\": start_date.strftime(\"%Y-%m-%d\"), \"lift\": lift}, ignore_index=True)\n",
    "\n",
    "    # Increment day\n",
    "    start_date += delta\n",
    "\n",
    "# Close cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Write to CSV\n",
    "daily_lift_df.to_csv(\"ANSWER_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
